{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11162267,"sourceType":"datasetVersion","datasetId":6965229}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:12.896597Z","iopub.execute_input":"2025-03-25T17:45:12.897008Z","iopub.status.idle":"2025-03-25T17:45:12.901772Z","shell.execute_reply.started":"2025-03-25T17:45:12.896972Z","shell.execute_reply":"2025-03-25T17:45:12.900608Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import cv2\nfrom skimage.feature import hog\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:12.926467Z","iopub.execute_input":"2025-03-25T17:45:12.926805Z","iopub.status.idle":"2025-03-25T17:45:12.931950Z","shell.execute_reply.started":"2025-03-25T17:45:12.926780Z","shell.execute_reply":"2025-03-25T17:45:12.930901Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Load images\nmask_path = \"/kaggle/input/abdataset/dataset/with_mask\"\nno_mask_path = \"/kaggle/input/abdataset/dataset/without_mask\"\n\ndef load_images(path, label):\n    data, labels = [], []\n    for filename in os.listdir(path):\n        file_path = os.path.join(path, filename)\n        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n\n        if img is None:  # Check if image is loaded properly\n            print(f\"Warning: Unable to read {file_path}\")\n            continue  # Skip this image\n\n        img = cv2.resize(img, (64, 64))  # Resize for consistency\n        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n        data.append(features)\n        labels.append(label)\n\n    return np.array(data), np.array(labels)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:12.933514Z","iopub.execute_input":"2025-03-25T17:45:12.933883Z","iopub.status.idle":"2025-03-25T17:45:12.945127Z","shell.execute_reply.started":"2025-03-25T17:45:12.933843Z","shell.execute_reply":"2025-03-25T17:45:12.944414Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Load both categories\nX_mask, y_mask = load_images(mask_path, 1)\nX_no_mask, y_no_mask = load_images(no_mask_path, 0)\n\n# Combine datasets\nX = np.vstack((X_mask, X_no_mask))\ny = np.hstack((y_mask, y_no_mask))\n\n# Split into training & test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:12.960212Z","iopub.execute_input":"2025-03-25T17:45:12.960572Z","iopub.status.idle":"2025-03-25T17:45:34.193410Z","shell.execute_reply.started":"2025-03-25T17:45:12.960534Z","shell.execute_reply":"2025-03-25T17:45:34.192202Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"svm_model = SVC(kernel='linear')\nsvm_model.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred_svm = svm_model.predict(X_test)\nsvm_accuracy = accuracy_score(y_test, y_pred_svm)\nprint(f\"SVM Accuracy: {svm_accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:34.194770Z","iopub.execute_input":"2025-03-25T17:45:34.195137Z","iopub.status.idle":"2025-03-25T17:45:39.004222Z","shell.execute_reply.started":"2025-03-25T17:45:34.195095Z","shell.execute_reply":"2025-03-25T17:45:39.003311Z"}},"outputs":[{"name":"stdout","text":"SVM Accuracy: 0.88\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"mlp_model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500)\nmlp_model.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred_mlp = mlp_model.predict(X_test)\nmlp_accuracy = accuracy_score(y_test, y_pred_mlp)\nprint(f\"MLP Accuracy: {mlp_accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:39.006226Z","iopub.execute_input":"2025-03-25T17:45:39.006501Z","iopub.status.idle":"2025-03-25T17:45:46.436203Z","shell.execute_reply.started":"2025-03-25T17:45:39.006479Z","shell.execute_reply":"2025-03-25T17:45:46.435279Z"}},"outputs":[{"name":"stdout","text":"MLP Accuracy: 0.92\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:46.437442Z","iopub.execute_input":"2025-03-25T17:45:46.437724Z","iopub.status.idle":"2025-03-25T17:45:46.442488Z","shell.execute_reply.started":"2025-03-25T17:45:46.437701Z","shell.execute_reply":"2025-03-25T17:45:46.441382Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Load images\ndef load_images_CNN(path, label):\n    data, labels = [], []\n    for filename in os.listdir(path):\n        file_path = os.path.join(path, filename)\n        img = cv2.imread(file_path)\n        if img is None:\n            print(f\"Warning: Skipping unreadable file {file_path}\")\n            continue\n        img = cv2.resize(img, (64, 64))  # Resize for CNN input\n        img = img / 255.0  # Normalize pixels to [0, 1]\n        data.append(img)\n        labels.append(label)\n    return np.array(data), np.array(labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:46.443268Z","iopub.execute_input":"2025-03-25T17:45:46.443545Z","iopub.status.idle":"2025-03-25T17:45:46.455943Z","shell.execute_reply.started":"2025-03-25T17:45:46.443522Z","shell.execute_reply":"2025-03-25T17:45:46.454680Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"X_mask_CNN, y_mask_CNN = load_images_CNN(mask_path, 1)\nX_no_mask_CNN, y_no_mask_CNN = load_images_CNN(no_mask_path, 0)\n\n# Combine datasets\nX_CNN = np.vstack((X_mask_CNN, X_no_mask_CNN))\ny_CNN = np.hstack((y_mask_CNN, y_no_mask_CNN))\n\n# Split into train (80%) and validation (20%)\nX_train_CNN, X_test_CNN, y_train_CNN, y_test_CNN = train_test_split(X_CNN, y_CNN, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:46.456986Z","iopub.execute_input":"2025-03-25T17:45:46.457312Z","iopub.status.idle":"2025-03-25T17:45:59.126568Z","shell.execute_reply.started":"2025-03-25T17:45:46.457282Z","shell.execute_reply":"2025-03-25T17:45:59.125540Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Experiment with different hyperparameters\nlearning_rates = [0.001, 0.0001]\nbatch_sizes = [32, 64, 128]\noptimizers = {'Adam': keras.optimizers.Adam, 'SGD': keras.optimizers.SGD}\nactivations = ['relu', 'leaky_relu', 'sigmoid']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:59.127584Z","iopub.execute_input":"2025-03-25T17:45:59.127837Z","iopub.status.idle":"2025-03-25T17:45:59.132290Z","shell.execute_reply.started":"2025-03-25T17:45:59.127816Z","shell.execute_reply":"2025-03-25T17:45:59.131238Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"for batch_size in batch_sizes:\n    for activation in activations:\n        for lr in learning_rates:\n            for opt_name, opt_class in optimizers.items():\n                print(f\"Training with batch_size={batch_size}, activation={activation}, learning_rate={lr}, optimizer={opt_name}\")\n                \n                model = keras.Sequential([\n                    layers.Conv2D(32, (3,3), activation=activation, input_shape=(64, 64, 3)),\n                    layers.MaxPooling2D(2,2),\n                    layers.Conv2D(64, (3,3), activation=activation),\n                    layers.MaxPooling2D(2,2),\n                    layers.Conv2D(128, (3,3), activation=activation),\n                    layers.MaxPooling2D(2,2),\n                    layers.Flatten(),\n                    layers.Dense(128, activation=activation),\n                    layers.Dropout(0.5),  # Prevent overfitting\n                    layers.Dense(1, activation=\"sigmoid\")  # Binary classification\n                ])\n\n                # Compile the model\n                optimizer = opt_class(learning_rate=lr)\n                model.compile(optimizer=optimizer,\n                              loss=\"binary_crossentropy\",\n                              metrics=[\"accuracy\"])\n\n                # Train the model\n                history = model.fit(X_train_CNN, y_train_CNN, epochs=10, batch_size=batch_size,\n                                    validation_data=(X_test_CNN, y_test_CNN))\n\n                # Evaluate the model\n                val_loss, val_acc = model.evaluate(X_test_CNN, y_test_CNN)\n                print(f\"Validation Accuracy: {val_acc:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:45:59.134364Z","iopub.execute_input":"2025-03-25T17:45:59.134633Z","iopub.status.idle":"2025-03-25T17:52:25.420935Z","shell.execute_reply.started":"2025-03-25T17:45:59.134609Z","shell.execute_reply":"2025-03-25T17:52:25.420104Z"}},"outputs":[{"name":"stdout","text":"Training with batch_size=32, activation=relu, learning_rate=0.001, optimizer=Adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7637 - loss: 0.4761 - val_accuracy: 0.8974 - val_loss: 0.2492\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.2655 - val_accuracy: 0.9011 - val_loss: 0.2553\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2111 - val_accuracy: 0.9243 - val_loss: 0.1955\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9381 - loss: 0.1627 - val_accuracy: 0.9487 - val_loss: 0.1412\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1456 - val_accuracy: 0.9426 - val_loss: 0.1733\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.0906 - val_accuracy: 0.9451 - val_loss: 0.1478\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.0981 - val_accuracy: 0.9512 - val_loss: 0.1372\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0823 - val_accuracy: 0.9609 - val_loss: 0.1057\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0559 - val_accuracy: 0.9548 - val_loss: 0.1055\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9763 - loss: 0.0558 - val_accuracy: 0.9573 - val_loss: 0.1354\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1306\nValidation Accuracy: 0.96\nTraining with batch_size=32, activation=relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4738 - loss: 0.6980 - val_accuracy: 0.4786 - val_loss: 0.6932\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4952 - loss: 0.6940 - val_accuracy: 0.5458 - val_loss: 0.6897\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 0.6914 - val_accuracy: 0.5519 - val_loss: 0.6870\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.6893 - val_accuracy: 0.5568 - val_loss: 0.6849\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5685 - loss: 0.6853 - val_accuracy: 0.5702 - val_loss: 0.6825\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 0.6823 - val_accuracy: 0.6081 - val_loss: 0.6802\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 0.6815 - val_accuracy: 0.5922 - val_loss: 0.6772\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6189 - loss: 0.6794 - val_accuracy: 0.6081 - val_loss: 0.6743\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6085 - loss: 0.6776 - val_accuracy: 0.6642 - val_loss: 0.6714\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.6738 - val_accuracy: 0.6679 - val_loss: 0.6676\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 0.6659\nValidation Accuracy: 0.67\nTraining with batch_size=32, activation=relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7018 - loss: 0.6046 - val_accuracy: 0.8364 - val_loss: 0.4024\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.3542 - val_accuracy: 0.8987 - val_loss: 0.2886\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8860 - loss: 0.2853 - val_accuracy: 0.9121 - val_loss: 0.2558\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8905 - loss: 0.2848 - val_accuracy: 0.9072 - val_loss: 0.2511\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.2303 - val_accuracy: 0.9194 - val_loss: 0.2349\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2182 - val_accuracy: 0.9182 - val_loss: 0.2139\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2029 - val_accuracy: 0.9206 - val_loss: 0.2049\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9359 - loss: 0.1910 - val_accuracy: 0.9267 - val_loss: 0.1888\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9408 - loss: 0.1689 - val_accuracy: 0.9280 - val_loss: 0.1801\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 0.1572 - val_accuracy: 0.9292 - val_loss: 0.1742\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.1812\nValidation Accuracy: 0.93\nTraining with batch_size=32, activation=relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4909 - loss: 0.6954 - val_accuracy: 0.3797 - val_loss: 0.6966\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4520 - loss: 0.6988 - val_accuracy: 0.3834 - val_loss: 0.6961\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4581 - loss: 0.6975 - val_accuracy: 0.3907 - val_loss: 0.6956\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 0.6967 - val_accuracy: 0.4054 - val_loss: 0.6951\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4661 - loss: 0.6964 - val_accuracy: 0.4457 - val_loss: 0.6946\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4904 - loss: 0.6937 - val_accuracy: 0.4701 - val_loss: 0.6942\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5021 - loss: 0.6931 - val_accuracy: 0.5067 - val_loss: 0.6937\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5155 - loss: 0.6930 - val_accuracy: 0.5287 - val_loss: 0.6933\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5031 - loss: 0.6937 - val_accuracy: 0.5299 - val_loss: 0.6929\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4939 - loss: 0.6942 - val_accuracy: 0.5336 - val_loss: 0.6924\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5387 - loss: 0.6926\nValidation Accuracy: 0.53\nTraining with batch_size=32, activation=leaky_relu, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7672 - loss: 0.4497 - val_accuracy: 0.9109 - val_loss: 0.2560\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.2396 - val_accuracy: 0.9280 - val_loss: 0.2021\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9420 - loss: 0.1624 - val_accuracy: 0.9451 - val_loss: 0.1530\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1099 - val_accuracy: 0.9451 - val_loss: 0.1354\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.0884 - val_accuracy: 0.9621 - val_loss: 0.1336\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9617 - loss: 0.1110 - val_accuracy: 0.9621 - val_loss: 0.1053\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0520 - val_accuracy: 0.9512 - val_loss: 0.1453\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0345 - val_accuracy: 0.9499 - val_loss: 0.1557\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0400 - val_accuracy: 0.9524 - val_loss: 0.1531\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0274 - val_accuracy: 0.9487 - val_loss: 0.1941\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.2183\nValidation Accuracy: 0.95\nTraining with batch_size=32, activation=leaky_relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5409 - loss: 0.6906 - val_accuracy: 0.6410 - val_loss: 0.6854\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5889 - loss: 0.6847 - val_accuracy: 0.6337 - val_loss: 0.6817\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5847 - loss: 0.6843 - val_accuracy: 0.6471 - val_loss: 0.6784\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6002 - loss: 0.6806 - val_accuracy: 0.6374 - val_loss: 0.6746\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6039 - loss: 0.6767 - val_accuracy: 0.6947 - val_loss: 0.6715\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6438 - loss: 0.6745 - val_accuracy: 0.6886 - val_loss: 0.6673\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6659 - loss: 0.6672 - val_accuracy: 0.7424 - val_loss: 0.6635\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6832 - loss: 0.6667 - val_accuracy: 0.7241 - val_loss: 0.6572\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6844 - loss: 0.6595 - val_accuracy: 0.7692 - val_loss: 0.6523\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7104 - loss: 0.6561 - val_accuracy: 0.7680 - val_loss: 0.6449\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.6420\nValidation Accuracy: 0.77\nTraining with batch_size=32, activation=leaky_relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.6697 - loss: 0.6306 - val_accuracy: 0.8730 - val_loss: 0.3611\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.3335 - val_accuracy: 0.8926 - val_loss: 0.3022\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8900 - loss: 0.2926 - val_accuracy: 0.8974 - val_loss: 0.2855\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8961 - loss: 0.2679 - val_accuracy: 0.9084 - val_loss: 0.2571\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9021 - loss: 0.2490 - val_accuracy: 0.9194 - val_loss: 0.2399\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9211 - loss: 0.2162 - val_accuracy: 0.9170 - val_loss: 0.2236\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9170 - loss: 0.2149 - val_accuracy: 0.9170 - val_loss: 0.2151\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.1943 - val_accuracy: 0.9158 - val_loss: 0.2109\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.1788 - val_accuracy: 0.9206 - val_loss: 0.2123\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.1748 - val_accuracy: 0.9243 - val_loss: 0.1824\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.1765\nValidation Accuracy: 0.92\nTraining with batch_size=32, activation=leaky_relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4837 - loss: 0.7010 - val_accuracy: 0.4469 - val_loss: 0.7020\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4870 - loss: 0.6964 - val_accuracy: 0.4469 - val_loss: 0.7006\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4974 - loss: 0.6996 - val_accuracy: 0.4469 - val_loss: 0.6993\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4883 - loss: 0.6964 - val_accuracy: 0.4493 - val_loss: 0.6983\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4938 - loss: 0.6966 - val_accuracy: 0.4505 - val_loss: 0.6973\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4887 - loss: 0.6964 - val_accuracy: 0.4530 - val_loss: 0.6964\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4985 - loss: 0.6960 - val_accuracy: 0.4603 - val_loss: 0.6956\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5023 - loss: 0.6944 - val_accuracy: 0.4799 - val_loss: 0.6949\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5024 - loss: 0.6933 - val_accuracy: 0.5067 - val_loss: 0.6942\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5071 - loss: 0.6957 - val_accuracy: 0.5189 - val_loss: 0.6936\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.6942\nValidation Accuracy: 0.52\nTraining with batch_size=32, activation=sigmoid, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.5100 - loss: 0.8458 - val_accuracy: 0.5531 - val_loss: 0.6901\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5230 - loss: 0.7081 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5284 - loss: 0.6963 - val_accuracy: 0.5531 - val_loss: 0.6909\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4964 - loss: 0.6982 - val_accuracy: 0.5531 - val_loss: 0.6912\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5053 - loss: 0.6940 - val_accuracy: 0.5531 - val_loss: 0.6919\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5255 - loss: 0.6926 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5113 - loss: 0.6939 - val_accuracy: 0.5531 - val_loss: 0.6916\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5101 - loss: 0.6937 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 0.6941 - val_accuracy: 0.5531 - val_loss: 0.6897\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5250 - loss: 0.6918 - val_accuracy: 0.5531 - val_loss: 0.6910\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5560 - loss: 0.6908\nValidation Accuracy: 0.55\nTraining with batch_size=32, activation=sigmoid, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4999 - loss: 0.7754 - val_accuracy: 0.5531 - val_loss: 0.6887\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4731 - loss: 0.7723 - val_accuracy: 0.5531 - val_loss: 0.6878\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5364 - loss: 0.7360 - val_accuracy: 0.5531 - val_loss: 0.6920\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5176 - loss: 0.7300 - val_accuracy: 0.5531 - val_loss: 0.6894\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4974 - loss: 0.7399 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5020 - loss: 0.7326 - val_accuracy: 0.5531 - val_loss: 0.6900\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5193 - loss: 0.7296 - val_accuracy: 0.5531 - val_loss: 0.6879\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5076 - loss: 0.7261 - val_accuracy: 0.5531 - val_loss: 0.6889\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5068 - loss: 0.7284 - val_accuracy: 0.5531 - val_loss: 0.6908\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4990 - loss: 0.7280 - val_accuracy: 0.5531 - val_loss: 0.6885\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 0.6882\nValidation Accuracy: 0.55\nTraining with batch_size=32, activation=sigmoid, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.5171 - loss: 0.7586 - val_accuracy: 0.5531 - val_loss: 0.6900\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4976 - loss: 0.7070 - val_accuracy: 0.5531 - val_loss: 0.6890\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4988 - loss: 0.6976 - val_accuracy: 0.5531 - val_loss: 0.6904\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4952 - loss: 0.6965 - val_accuracy: 0.4469 - val_loss: 0.6937\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5198 - loss: 0.6923 - val_accuracy: 0.5531 - val_loss: 0.6885\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5241 - loss: 0.6924 - val_accuracy: 0.5531 - val_loss: 0.6891\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5151 - loss: 0.6929 - val_accuracy: 0.5531 - val_loss: 0.6898\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5211 - loss: 0.6917 - val_accuracy: 0.5531 - val_loss: 0.6877\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5180 - loss: 0.6936 - val_accuracy: 0.5531 - val_loss: 0.6914\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5280 - loss: 0.6932 - val_accuracy: 0.5531 - val_loss: 0.6915\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 0.6915\nValidation Accuracy: 0.55\nTraining with batch_size=32, activation=sigmoid, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5038 - loss: 0.7757 - val_accuracy: 0.4469 - val_loss: 0.7099\nEpoch 2/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5184 - loss: 0.7457 - val_accuracy: 0.4469 - val_loss: 0.6996\nEpoch 3/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4950 - loss: 0.7645 - val_accuracy: 0.4469 - val_loss: 0.6949\nEpoch 4/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5027 - loss: 0.7571 - val_accuracy: 0.5531 - val_loss: 0.6923\nEpoch 5/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5143 - loss: 0.7490 - val_accuracy: 0.5531 - val_loss: 0.6907\nEpoch 6/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5024 - loss: 0.7487 - val_accuracy: 0.5531 - val_loss: 0.6901\nEpoch 7/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4815 - loss: 0.7739 - val_accuracy: 0.5531 - val_loss: 0.6896\nEpoch 8/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5212 - loss: 0.7371 - val_accuracy: 0.5531 - val_loss: 0.6896\nEpoch 9/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5084 - loss: 0.7510 - val_accuracy: 0.5531 - val_loss: 0.6894\nEpoch 10/10\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4831 - loss: 0.7639 - val_accuracy: 0.5531 - val_loss: 0.6892\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 0.6889\nValidation Accuracy: 0.55\nTraining with batch_size=64, activation=relu, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7220 - loss: 0.5262 - val_accuracy: 0.9023 - val_loss: 0.2638\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8996 - loss: 0.2644 - val_accuracy: 0.9096 - val_loss: 0.2526\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9102 - loss: 0.2308 - val_accuracy: 0.9219 - val_loss: 0.2043\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9278 - loss: 0.1953 - val_accuracy: 0.9292 - val_loss: 0.1869\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9424 - loss: 0.1488 - val_accuracy: 0.9121 - val_loss: 0.2516\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.1458 - val_accuracy: 0.9438 - val_loss: 0.1487\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.1108 - val_accuracy: 0.9377 - val_loss: 0.1616\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9547 - loss: 0.1229 - val_accuracy: 0.9597 - val_loss: 0.1119\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0621 - val_accuracy: 0.9621 - val_loss: 0.1218\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9777 - loss: 0.0570 - val_accuracy: 0.9475 - val_loss: 0.1421\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9468 - loss: 0.1392\nValidation Accuracy: 0.95\nTraining with batch_size=64, activation=relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5131 - loss: 0.6915 - val_accuracy: 0.5556 - val_loss: 0.6877\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5165 - loss: 0.6918 - val_accuracy: 0.5653 - val_loss: 0.6854\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5578 - loss: 0.6859 - val_accuracy: 0.5983 - val_loss: 0.6830\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5627 - loss: 0.6870 - val_accuracy: 0.6093 - val_loss: 0.6807\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5794 - loss: 0.6837 - val_accuracy: 0.6142 - val_loss: 0.6785\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5845 - loss: 0.6813 - val_accuracy: 0.6300 - val_loss: 0.6767\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5924 - loss: 0.6818 - val_accuracy: 0.6679 - val_loss: 0.6748\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5973 - loss: 0.6808 - val_accuracy: 0.6899 - val_loss: 0.6728\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6259 - loss: 0.6770 - val_accuracy: 0.6911 - val_loss: 0.6703\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6580 - loss: 0.6722 - val_accuracy: 0.6642 - val_loss: 0.6673\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6952 - loss: 0.6664\nValidation Accuracy: 0.66\nTraining with batch_size=64, activation=relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6169 - loss: 0.6614 - val_accuracy: 0.8168 - val_loss: 0.4836\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8231 - loss: 0.4533 - val_accuracy: 0.8742 - val_loss: 0.3370\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8897 - loss: 0.3157 - val_accuracy: 0.9035 - val_loss: 0.2925\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8827 - loss: 0.3047 - val_accuracy: 0.9121 - val_loss: 0.2679\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8941 - loss: 0.2837 - val_accuracy: 0.9158 - val_loss: 0.2554\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9130 - loss: 0.2488 - val_accuracy: 0.9109 - val_loss: 0.2473\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9102 - loss: 0.2430 - val_accuracy: 0.9158 - val_loss: 0.2349\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.2224 - val_accuracy: 0.9219 - val_loss: 0.2173\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.2103 - val_accuracy: 0.9328 - val_loss: 0.2058\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9217 - loss: 0.1989 - val_accuracy: 0.9316 - val_loss: 0.1910\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9364 - loss: 0.1925\nValidation Accuracy: 0.93\nTraining with batch_size=64, activation=relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5112 - loss: 0.6932 - val_accuracy: 0.6093 - val_loss: 0.6916\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5313 - loss: 0.6918 - val_accuracy: 0.6190 - val_loss: 0.6913\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5138 - loss: 0.6923 - val_accuracy: 0.6166 - val_loss: 0.6911\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5460 - loss: 0.6908 - val_accuracy: 0.6215 - val_loss: 0.6909\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5209 - loss: 0.6915 - val_accuracy: 0.6276 - val_loss: 0.6907\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5246 - loss: 0.6920 - val_accuracy: 0.6288 - val_loss: 0.6905\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5293 - loss: 0.6920 - val_accuracy: 0.6276 - val_loss: 0.6903\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5330 - loss: 0.6916 - val_accuracy: 0.6300 - val_loss: 0.6901\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5271 - loss: 0.6920 - val_accuracy: 0.6361 - val_loss: 0.6899\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5280 - loss: 0.6909 - val_accuracy: 0.6422 - val_loss: 0.6897\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6547 - loss: 0.6896\nValidation Accuracy: 0.64\nTraining with batch_size=64, activation=leaky_relu, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7289 - loss: 0.5291 - val_accuracy: 0.8926 - val_loss: 0.3184\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9051 - loss: 0.2598 - val_accuracy: 0.9023 - val_loss: 0.2615\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9292 - loss: 0.1969 - val_accuracy: 0.9402 - val_loss: 0.1930\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1687 - val_accuracy: 0.9365 - val_loss: 0.1764\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.1150 - val_accuracy: 0.9536 - val_loss: 0.1148\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9636 - loss: 0.0922 - val_accuracy: 0.9499 - val_loss: 0.1439\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0736 - val_accuracy: 0.9548 - val_loss: 0.1135\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.0835 - val_accuracy: 0.9597 - val_loss: 0.1101\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.0438 - val_accuracy: 0.9548 - val_loss: 0.1298\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0564 - val_accuracy: 0.9573 - val_loss: 0.1298\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9597 - loss: 0.1356\nValidation Accuracy: 0.96\nTraining with batch_size=64, activation=leaky_relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4864 - loss: 0.6979 - val_accuracy: 0.5617 - val_loss: 0.6899\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5329 - loss: 0.6909 - val_accuracy: 0.6068 - val_loss: 0.6859\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5495 - loss: 0.6882 - val_accuracy: 0.5995 - val_loss: 0.6830\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5416 - loss: 0.6866 - val_accuracy: 0.5971 - val_loss: 0.6809\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5660 - loss: 0.6862 - val_accuracy: 0.6007 - val_loss: 0.6788\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5710 - loss: 0.6824 - val_accuracy: 0.5958 - val_loss: 0.6764\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5768 - loss: 0.6817 - val_accuracy: 0.5824 - val_loss: 0.6741\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5878 - loss: 0.6772 - val_accuracy: 0.6422 - val_loss: 0.6728\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6007 - loss: 0.6766 - val_accuracy: 0.6361 - val_loss: 0.6704\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6328 - loss: 0.6726 - val_accuracy: 0.6117 - val_loss: 0.6678\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6386 - loss: 0.6658\nValidation Accuracy: 0.61\nTraining with batch_size=64, activation=leaky_relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.6880 - loss: 0.6224 - val_accuracy: 0.8584 - val_loss: 0.3905\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8450 - loss: 0.3881 - val_accuracy: 0.8559 - val_loss: 0.3595\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8847 - loss: 0.3196 - val_accuracy: 0.8987 - val_loss: 0.2928\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8905 - loss: 0.3063 - val_accuracy: 0.8987 - val_loss: 0.2770\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.2600 - val_accuracy: 0.8974 - val_loss: 0.2678\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9042 - loss: 0.2636 - val_accuracy: 0.8962 - val_loss: 0.2721\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9009 - loss: 0.2708 - val_accuracy: 0.9133 - val_loss: 0.2399\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9146 - loss: 0.2289 - val_accuracy: 0.9035 - val_loss: 0.2562\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9138 - loss: 0.2214 - val_accuracy: 0.9194 - val_loss: 0.2164\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9275 - loss: 0.1910 - val_accuracy: 0.9035 - val_loss: 0.2417\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9068 - loss: 0.2337\nValidation Accuracy: 0.90\nTraining with batch_size=64, activation=leaky_relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4934 - loss: 0.7130 - val_accuracy: 0.4469 - val_loss: 0.7216\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4853 - loss: 0.7137 - val_accuracy: 0.4481 - val_loss: 0.7159\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4699 - loss: 0.7143 - val_accuracy: 0.4493 - val_loss: 0.7113\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4939 - loss: 0.7056 - val_accuracy: 0.4542 - val_loss: 0.7076\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4920 - loss: 0.7045 - val_accuracy: 0.4615 - val_loss: 0.7043\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4790 - loss: 0.7040 - val_accuracy: 0.4676 - val_loss: 0.7018\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4959 - loss: 0.6984 - val_accuracy: 0.4762 - val_loss: 0.6995\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4880 - loss: 0.7015 - val_accuracy: 0.4896 - val_loss: 0.6976\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5069 - loss: 0.6956 - val_accuracy: 0.5128 - val_loss: 0.6960\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5122 - loss: 0.6962 - val_accuracy: 0.5421 - val_loss: 0.6946\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5157 - loss: 0.6942\nValidation Accuracy: 0.54\nTraining with batch_size=64, activation=sigmoid, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5165 - loss: 0.9099 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5150 - loss: 0.7132 - val_accuracy: 0.5531 - val_loss: 0.6888\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5110 - loss: 0.7031 - val_accuracy: 0.4469 - val_loss: 0.6946\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5119 - loss: 0.6948 - val_accuracy: 0.5531 - val_loss: 0.6886\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5070 - loss: 0.6940 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5110 - loss: 0.6951 - val_accuracy: 0.5531 - val_loss: 0.6877\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5255 - loss: 0.6929 - val_accuracy: 0.5531 - val_loss: 0.6890\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.5531 - val_loss: 0.6926\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5042 - loss: 0.6939 - val_accuracy: 0.5531 - val_loss: 0.6897\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5025 - loss: 0.6942 - val_accuracy: 0.5531 - val_loss: 0.6889\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6886\nValidation Accuracy: 0.55\nTraining with batch_size=64, activation=sigmoid, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.5256 - loss: 0.9440 - val_accuracy: 0.5531 - val_loss: 0.6929\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5090 - loss: 0.7464 - val_accuracy: 0.5531 - val_loss: 0.6880\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5129 - loss: 0.7474 - val_accuracy: 0.5531 - val_loss: 0.6889\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5152 - loss: 0.7417 - val_accuracy: 0.5531 - val_loss: 0.6880\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4902 - loss: 0.7550 - val_accuracy: 0.5531 - val_loss: 0.6881\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 0.7390 - val_accuracy: 0.5531 - val_loss: 0.6899\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5226 - loss: 0.7284 - val_accuracy: 0.5531 - val_loss: 0.6896\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4991 - loss: 0.7351 - val_accuracy: 0.5531 - val_loss: 0.6903\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4966 - loss: 0.7417 - val_accuracy: 0.5531 - val_loss: 0.6895\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4719 - loss: 0.7437 - val_accuracy: 0.5531 - val_loss: 0.6885\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6881\nValidation Accuracy: 0.55\nTraining with batch_size=64, activation=sigmoid, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5343 - loss: 0.7313 - val_accuracy: 0.4469 - val_loss: 0.6981\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5253 - loss: 0.7038 - val_accuracy: 0.5531 - val_loss: 0.6883\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4999 - loss: 0.7001 - val_accuracy: 0.5531 - val_loss: 0.6890\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5242 - loss: 0.6931 - val_accuracy: 0.5531 - val_loss: 0.6883\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5247 - loss: 0.6935 - val_accuracy: 0.4469 - val_loss: 0.6954\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5040 - loss: 0.6945 - val_accuracy: 0.5531 - val_loss: 0.6883\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5215 - loss: 0.6942 - val_accuracy: 0.5531 - val_loss: 0.6911\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5129 - loss: 0.6920 - val_accuracy: 0.5531 - val_loss: 0.6879\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5212 - loss: 0.6922 - val_accuracy: 0.5531 - val_loss: 0.6902\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4864 - loss: 0.6951 - val_accuracy: 0.5531 - val_loss: 0.6885\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6882\nValidation Accuracy: 0.55\nTraining with batch_size=64, activation=sigmoid, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4942 - loss: 0.7755 - val_accuracy: 0.4469 - val_loss: 0.6990\nEpoch 2/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4906 - loss: 0.7777 - val_accuracy: 0.4469 - val_loss: 0.6970\nEpoch 3/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4969 - loss: 0.7726 - val_accuracy: 0.4469 - val_loss: 0.6952\nEpoch 4/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4866 - loss: 0.7773 - val_accuracy: 0.4469 - val_loss: 0.6941\nEpoch 5/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4979 - loss: 0.7678 - val_accuracy: 0.5531 - val_loss: 0.6930\nEpoch 6/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5015 - loss: 0.7617 - val_accuracy: 0.5531 - val_loss: 0.6922\nEpoch 7/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5182 - loss: 0.7542 - val_accuracy: 0.5531 - val_loss: 0.6915\nEpoch 8/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4848 - loss: 0.7728 - val_accuracy: 0.5531 - val_loss: 0.6912\nEpoch 9/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5030 - loss: 0.7633 - val_accuracy: 0.5531 - val_loss: 0.6905\nEpoch 10/10\n\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5332 - loss: 0.7496 - val_accuracy: 0.5531 - val_loss: 0.6902\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6900\nValidation Accuracy: 0.55\nTraining with batch_size=128, activation=relu, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.6649 - loss: 0.6096 - val_accuracy: 0.8913 - val_loss: 0.3045\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8886 - loss: 0.3129 - val_accuracy: 0.9084 - val_loss: 0.2634\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9123 - loss: 0.2436 - val_accuracy: 0.9109 - val_loss: 0.2377\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9239 - loss: 0.1982 - val_accuracy: 0.9109 - val_loss: 0.2357\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9240 - loss: 0.2025 - val_accuracy: 0.9353 - val_loss: 0.1708\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9430 - loss: 0.1485 - val_accuracy: 0.9426 - val_loss: 0.1569\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9544 - loss: 0.1288 - val_accuracy: 0.9451 - val_loss: 0.1380\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9553 - loss: 0.1249 - val_accuracy: 0.9548 - val_loss: 0.1348\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9574 - loss: 0.1098 - val_accuracy: 0.9548 - val_loss: 0.1195\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9716 - loss: 0.0811 - val_accuracy: 0.9536 - val_loss: 0.1162\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.1225\nValidation Accuracy: 0.95\nTraining with batch_size=128, activation=relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.5131 - loss: 0.6935 - val_accuracy: 0.5519 - val_loss: 0.6895\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5008 - loss: 0.6944 - val_accuracy: 0.5519 - val_loss: 0.6886\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5499 - loss: 0.6896 - val_accuracy: 0.5519 - val_loss: 0.6876\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6913 - val_accuracy: 0.5519 - val_loss: 0.6866\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5249 - loss: 0.6910 - val_accuracy: 0.5519 - val_loss: 0.6856\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5446 - loss: 0.6888 - val_accuracy: 0.5519 - val_loss: 0.6845\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5262 - loss: 0.6910 - val_accuracy: 0.5543 - val_loss: 0.6835\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5588 - loss: 0.6863 - val_accuracy: 0.5556 - val_loss: 0.6824\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5491 - loss: 0.6877 - val_accuracy: 0.5604 - val_loss: 0.6815\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5560 - loss: 0.6867 - val_accuracy: 0.5653 - val_loss: 0.6806\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5755 - loss: 0.6795\nValidation Accuracy: 0.57\nTraining with batch_size=128, activation=relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.5349 - loss: 0.6839 - val_accuracy: 0.7717 - val_loss: 0.6186\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7848 - loss: 0.5878 - val_accuracy: 0.8486 - val_loss: 0.4503\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8497 - loss: 0.4265 - val_accuracy: 0.8681 - val_loss: 0.3598\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8707 - loss: 0.3570 - val_accuracy: 0.8913 - val_loss: 0.3095\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8893 - loss: 0.3115 - val_accuracy: 0.8913 - val_loss: 0.2893\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8958 - loss: 0.2844 - val_accuracy: 0.9096 - val_loss: 0.2634\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8947 - loss: 0.2799 - val_accuracy: 0.9096 - val_loss: 0.2529\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8963 - loss: 0.2625 - val_accuracy: 0.9158 - val_loss: 0.2403\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9125 - loss: 0.2314 - val_accuracy: 0.9219 - val_loss: 0.2305\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9190 - loss: 0.2226 - val_accuracy: 0.9219 - val_loss: 0.2215\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9331 - loss: 0.2130\nValidation Accuracy: 0.92\nTraining with batch_size=128, activation=relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.5348 - loss: 0.6900 - val_accuracy: 0.5531 - val_loss: 0.6886\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5445 - loss: 0.6897 - val_accuracy: 0.5531 - val_loss: 0.6885\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5467 - loss: 0.6905 - val_accuracy: 0.5531 - val_loss: 0.6885\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5254 - loss: 0.6917 - val_accuracy: 0.5531 - val_loss: 0.6884\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5303 - loss: 0.6903 - val_accuracy: 0.5531 - val_loss: 0.6884\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5421 - loss: 0.6895 - val_accuracy: 0.5543 - val_loss: 0.6883\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5373 - loss: 0.6904 - val_accuracy: 0.5543 - val_loss: 0.6882\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5174 - loss: 0.6909 - val_accuracy: 0.5543 - val_loss: 0.6882\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5271 - loss: 0.6901 - val_accuracy: 0.5543 - val_loss: 0.6881\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5438 - loss: 0.6900 - val_accuracy: 0.5543 - val_loss: 0.6881\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5573 - loss: 0.6878\nValidation Accuracy: 0.55\nTraining with batch_size=128, activation=leaky_relu, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.6965 - loss: 0.5597 - val_accuracy: 0.8950 - val_loss: 0.3327\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8888 - loss: 0.3068 - val_accuracy: 0.8987 - val_loss: 0.2517\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9101 - loss: 0.2347 - val_accuracy: 0.9084 - val_loss: 0.2350\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9311 - loss: 0.1920 - val_accuracy: 0.9280 - val_loss: 0.1997\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9350 - loss: 0.1681 - val_accuracy: 0.9060 - val_loss: 0.2675\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9470 - loss: 0.1543 - val_accuracy: 0.9243 - val_loss: 0.1890\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9558 - loss: 0.1267 - val_accuracy: 0.9414 - val_loss: 0.1501\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9650 - loss: 0.0860 - val_accuracy: 0.9560 - val_loss: 0.1277\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9722 - loss: 0.0790 - val_accuracy: 0.9524 - val_loss: 0.1211\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9750 - loss: 0.0692 - val_accuracy: 0.9597 - val_loss: 0.1063\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9588 - loss: 0.1087\nValidation Accuracy: 0.96\nTraining with batch_size=128, activation=leaky_relu, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.5332 - loss: 0.6900 - val_accuracy: 0.5531 - val_loss: 0.6820\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5299 - loss: 0.6881 - val_accuracy: 0.5531 - val_loss: 0.6805\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5486 - loss: 0.6857 - val_accuracy: 0.5531 - val_loss: 0.6791\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5682 - loss: 0.6825 - val_accuracy: 0.5580 - val_loss: 0.6777\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5455 - loss: 0.6849 - val_accuracy: 0.5617 - val_loss: 0.6762\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5681 - loss: 0.6813 - val_accuracy: 0.5726 - val_loss: 0.6747\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5650 - loss: 0.6790 - val_accuracy: 0.5873 - val_loss: 0.6731\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5917 - loss: 0.6771 - val_accuracy: 0.6044 - val_loss: 0.6716\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5836 - loss: 0.6758 - val_accuracy: 0.6142 - val_loss: 0.6698\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6175 - loss: 0.6727 - val_accuracy: 0.6252 - val_loss: 0.6679\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6501 - loss: 0.6665\nValidation Accuracy: 0.63\nTraining with batch_size=128, activation=leaky_relu, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.5888 - loss: 0.6730 - val_accuracy: 0.7937 - val_loss: 0.5794\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7726 - loss: 0.5483 - val_accuracy: 0.8523 - val_loss: 0.4198\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8439 - loss: 0.4060 - val_accuracy: 0.8730 - val_loss: 0.3567\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8727 - loss: 0.3484 - val_accuracy: 0.8889 - val_loss: 0.3195\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8812 - loss: 0.3253 - val_accuracy: 0.8913 - val_loss: 0.2972\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8961 - loss: 0.2925 - val_accuracy: 0.9072 - val_loss: 0.2832\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8955 - loss: 0.2755 - val_accuracy: 0.9035 - val_loss: 0.2682\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9015 - loss: 0.2699 - val_accuracy: 0.9084 - val_loss: 0.2560\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9078 - loss: 0.2552 - val_accuracy: 0.9121 - val_loss: 0.2466\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9104 - loss: 0.2355 - val_accuracy: 0.9133 - val_loss: 0.2380\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9192 - loss: 0.2271\nValidation Accuracy: 0.91\nTraining with batch_size=128, activation=leaky_relu, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - accuracy: 0.5273 - loss: 0.6925 - val_accuracy: 0.5885 - val_loss: 0.6922\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5405 - loss: 0.6909 - val_accuracy: 0.6007 - val_loss: 0.6920\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5168 - loss: 0.6934 - val_accuracy: 0.6020 - val_loss: 0.6917\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5036 - loss: 0.6935 - val_accuracy: 0.6007 - val_loss: 0.6915\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5084 - loss: 0.6923 - val_accuracy: 0.6105 - val_loss: 0.6914\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5154 - loss: 0.6950 - val_accuracy: 0.6166 - val_loss: 0.6911\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5300 - loss: 0.6912 - val_accuracy: 0.6178 - val_loss: 0.6909\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5171 - loss: 0.6942 - val_accuracy: 0.6166 - val_loss: 0.6907\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5105 - loss: 0.6937 - val_accuracy: 0.6154 - val_loss: 0.6905\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5451 - loss: 0.6914 - val_accuracy: 0.6166 - val_loss: 0.6904\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6258 - loss: 0.6899\nValidation Accuracy: 0.62\nTraining with batch_size=128, activation=sigmoid, learning_rate=0.001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.5120 - loss: 1.1241 - val_accuracy: 0.5531 - val_loss: 0.6877\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4940 - loss: 0.7404 - val_accuracy: 0.5531 - val_loss: 0.6900\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4992 - loss: 0.7354 - val_accuracy: 0.5531 - val_loss: 0.6909\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5077 - loss: 0.7028 - val_accuracy: 0.5531 - val_loss: 0.6908\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5137 - loss: 0.6949 - val_accuracy: 0.5531 - val_loss: 0.6874\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6935 - val_accuracy: 0.5531 - val_loss: 0.6877\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5166 - loss: 0.6947 - val_accuracy: 0.5531 - val_loss: 0.6899\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5298 - loss: 0.6913 - val_accuracy: 0.5531 - val_loss: 0.6909\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5006 - loss: 0.6936 - val_accuracy: 0.5531 - val_loss: 0.6885\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5177 - loss: 0.6917 - val_accuracy: 0.5531 - val_loss: 0.6883\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5560 - loss: 0.6879\nValidation Accuracy: 0.55\nTraining with batch_size=128, activation=sigmoid, learning_rate=0.001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.4925 - loss: 0.8017 - val_accuracy: 0.4469 - val_loss: 0.6972\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5135 - loss: 0.7860 - val_accuracy: 0.5531 - val_loss: 0.6907\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4996 - loss: 0.7682 - val_accuracy: 0.5531 - val_loss: 0.6891\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4906 - loss: 0.7789 - val_accuracy: 0.5531 - val_loss: 0.6886\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4862 - loss: 0.7794 - val_accuracy: 0.5531 - val_loss: 0.6892\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5027 - loss: 0.7671 - val_accuracy: 0.5531 - val_loss: 0.6889\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4961 - loss: 0.7643 - val_accuracy: 0.5531 - val_loss: 0.6894\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4941 - loss: 0.7562 - val_accuracy: 0.5531 - val_loss: 0.6895\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5039 - loss: 0.7572 - val_accuracy: 0.5531 - val_loss: 0.6901\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5178 - loss: 0.7574 - val_accuracy: 0.5531 - val_loss: 0.6898\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6896\nValidation Accuracy: 0.55\nTraining with batch_size=128, activation=sigmoid, learning_rate=0.0001, optimizer=Adam\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.5148 - loss: 0.7306 - val_accuracy: 0.4469 - val_loss: 0.7007\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4978 - loss: 0.7129 - val_accuracy: 0.5531 - val_loss: 0.6885\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5110 - loss: 0.7021 - val_accuracy: 0.5531 - val_loss: 0.6899\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5309 - loss: 0.6924 - val_accuracy: 0.5531 - val_loss: 0.6879\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5075 - loss: 0.6970 - val_accuracy: 0.5531 - val_loss: 0.6927\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5050 - loss: 0.6949 - val_accuracy: 0.4469 - val_loss: 0.6941\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4842 - loss: 0.6972 - val_accuracy: 0.5531 - val_loss: 0.6902\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5203 - loss: 0.6915 - val_accuracy: 0.5531 - val_loss: 0.6900\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5113 - loss: 0.6930 - val_accuracy: 0.5531 - val_loss: 0.6899\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5060 - loss: 0.6926 - val_accuracy: 0.5531 - val_loss: 0.6887\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6884\nValidation Accuracy: 0.55\nTraining with batch_size=128, activation=sigmoid, learning_rate=0.0001, optimizer=SGD\nEpoch 1/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.5098 - loss: 0.7505 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 2/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.7389 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 3/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4893 - loss: 0.7492 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 4/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4947 - loss: 0.7605 - val_accuracy: 0.5531 - val_loss: 0.6875\nEpoch 5/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4917 - loss: 0.7623 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 6/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4886 - loss: 0.7539 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 7/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5195 - loss: 0.7388 - val_accuracy: 0.5531 - val_loss: 0.6876\nEpoch 8/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5010 - loss: 0.7504 - val_accuracy: 0.5531 - val_loss: 0.6877\nEpoch 9/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5068 - loss: 0.7446 - val_accuracy: 0.5531 - val_loss: 0.6878\nEpoch 10/10\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4811 - loss: 0.7623 - val_accuracy: 0.5531 - val_loss: 0.6878\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5560 - loss: 0.6873\nValidation Accuracy: 0.55\n","output_type":"stream"}],"execution_count":35}]}